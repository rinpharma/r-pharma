day,time,type,title,abstract,author,affiliation,slides,youtube
1,8:15 AM,coffee-session,Package Management,,Devin Pastoor,Metrum Research Group,,
1,8:15 AM,coffee-session,R Education in Pharma,,Paulo Bargo // Satish Murthy,Janssen // Janssen,,
1,8:15 AM,coffee-session,R and Python Interoperability,,Sean Lopp,RStudio,,
1,8:45 AM,break,Break,,,,,
1,9:00 AM,opening-remarks,Opening Remarks,,Merce Crosas,Harvard University,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Crosas-Opening_Remarks_Day_1.pdf,
1,9:15 AM,keynote,Reproducibility and the role of code in reproducible data science,,Garrett Grolemund,RStudio,,
1,10:00 AM,talk,Using R for Generic Drug Evaluation and SABE R-package for Assessing Bioequivalence of Topical Dermatological Products,"Determination of bioequivalence (BE), a crucial part of the evaluation of generic drugs, may depend on clinical endpoint studies, pharmacokinetic (PK) studies of bioavailability, and In-Vitro tests, among others. Additionally, in reviewing Abbreviated New Drug Applications (ANDA), FDA reviewers often analyze safety studies and perform various kinds of simulations. A growing, vibrant group of statisticians in the Office of Biostatistics, CDER/FDA has adopted R for both their routine tasks and to address numerous scientific questions that are received in the form of internal consults. During the past 5 years, we have used R to run power simulations; generate the distribution of certain statistics of interest; assess the similarity of and cluster amino-acid sequences as well as, derive the distribution of the molecular weight of such sequences of a certain length; and determine the validity of data sets categorized for genotoxicity. R-package SABE was developed to accompany a new statistical test, used to assess BE of topical dermatological products when data for evaluation come from the In-Vitro Permeation Test (IVPT) [1]. BE tests consider comparisons between a Test (usually generic) and a Reference (RLD) product under a replicate study design. A function that assesses BE of a Test and a Reference formulation uses a mixed scaled criterion for the PK metrics AUC (Area Under the Curve) and Cmax (maximum concentration).",Elena Rantou,FDA,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Rantou-Generic_Drug_Evaluation_Bioequivalence_Topical_Dermatological_Products.pdf,
1,10:20 AM,talk,"How to win friends and influence people: Efficiency, Reproducibility, and Scalability with R Project templates and parameterized R Markdown","Our bioinformatics team is relied upon to quickly generate information to drive business decisions, allocate resources, and develop predictive models. As such, we constantly strive to streamline our work and create efficiencies when possible. To this end, we have developed a set of tools utilizing R packages, project templates, and parameterized R Markdown reports that enables a semi-automated, standardized modeling work flow. These tools have largely increased our output in generating informative metrics, improved our ability to reproduce our results, and empowered us to scale our team in a way that supports our company goals.",Leigh Alexander,SomaLogic,,
1,10:30 AM,talk,Teaching an old dog new tricks: modernizing gsDesign,"The gsDesign package for group sequential design is widely used with >30k downloads. The package was originally written in 2007 with substantial documentation and Runit testing created before 2010. A Shiny interface was created to make the package more approachable in about 2015. Recent efforts have focused on updating package to use Roxygen2, pkgdown, covr/covrpage and testthat as well as changing vignettes from Sweave to R Markdown. The learning curve for this modernization will be discussed as well as usage in a regulated environment.",Keaven Anderson,Merck,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Anderson-Modernizing_gsDesign.pptx,
1,10:50 AM,break,Break,,,,,
1,11:10 AM,talk,nlmixr: an R package for population PKPD modeling,"nlmixr is a free and open source R package for fitting nonlinear pharmacokinetic (PK), pharmacodynamic (PD), joint PK/PD and quantitative systems pharmacology (QSP) mixed-effects models. Currently, nlmixr is capable of fitting both traditional compartmental PK models as well as more complex models implemented using ordinary differential equations (ODEs). It is under intensive development and has succeeded in attracting extensive attention and a willingness to make contributions from the pharmaceutical modeling community. We believe that, over time, it will become a capable, credible alternative to commercial software tools, such as NONMEM, Monolix, and Phoenix NLME.",Mirjam Trame,Novartis,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Trame-nlmixr.pdf,
1,11:30 AM,talk,Creating and reviving Shiny apps with {golem},"Developing Shiny applications that meet design goals, easily deploy to multiple platforms, and contain easily maintainable components (all while adhering to best practices) is typically a difficult endeavor. Until recently, there has not been a tool addressing the optimal development workflow and construction of Shiny apps. The {golem} package by Think-R offers an opinionated framework for creating a Shiny app as a package, with {usethis}-like functionality to add a diverse set of capabilities. In this presentation, I will share how {golem} enables a robust standard for Shiny development and how it magically brought a dormant application back to life.",Eric Nantz,Eli Lilly,https://rpodcast.gitlab.io/golem_rpharma2019/#1,
1,11:40 AM,talk,Exploratory Graphics (xGx): Promoting the purposeful exploration of PKPD data,"Introduction: As pharmacometricians, we sometimes jump into complex modeling before thoroughly exploring our data. This can happen due to tight timelines, lack of ready-to-use graphic tools or enthusiasm for complex models. Exploratory plots can help to uncover useful insights in the data and identify aspects to be explored further through modeling or in future studies. Exploratory plots can even quickly answer questions without the need of a complex model, improving our efficiency and providing timely impact on project strategy. The Exploratory Graphics (xGx) tool is an open-source R-based tool, freely available on GitHub [1]. Intuitively organized by datatype and driven by analysis questions, the tool aims to encourage a question-based approach to data exploration focusing on the key questions relevant to dose-exposure-response analyses. 
Objectives:  
  -  Facilitate the purposeful exploration of PKPD data 
  -  Encourage a question-based approach to data exploration, focusing on dose-exposure-response relationships 
  -  Provide a teaching tool for people new to PKPD analysis 

Methods: PK (single and multiple ascending dose), and PD (continuous, time-to-event, categorical, count, and ordinal) data were simulated and formatted according to a typical PKPD modeling dataset format. Lists of key questions relevant to dose-exposure-response exploration were compiled, and exploratory plots were generated to answer each question. The graphs were created following good graphics principles to ensure quality and consistency in our graphical communications [2]. 

Results: Examples of the key analysis questions include: 
  -  Provide an overview of the data: - What type of data is it (e.g. continuous, binary, categorical)? - How many doses? - What is the range of doses explored? - For PK data, how many potential compartments are observed? - Is the exposure dose-proportional? - Is there evidence of nonlinearity in clearance? 
  -  Assess the variability: - How large is the between subject variability compared to between dose separation? - Can any of the between subject variability be attributed to any covariates? - Are there any patterns in the within subject variability (e.g. circadian rhythms, seasonal effects, food effects, underlying disease progression)? 
  -  Assess the dose/exposure-response relationship: - Is there evidence of a correlation between dose/exposure and response? - Is the relationship positive or negative? - Is there a plateau or maximal effect in the observed dose/exposure range? - Is there evidence of a delay between exposure and response? 

For each datatype in the simulated dataset, plots were generated to answer these key questions. The plots along with the codes to produce them were compiled into a user friendly interface. The tool is intuitively organized by datatype and driven by the analysis questions. Since the graphs were generated based on a typical modeling dataset format and hosted online, they can be easily accessed and applied to new projects. Conclusion: Exploratory plots were generated, built around typical key questions particularly relevant to dose-exposure-response exploration and compiled into a user friendly interface. The Exploratory Graphics (xGx) tool can help underscore the role of purposeful data exploration for quantitative scientists. Through a question-based approach, xGx helps uncover useful insights that can be revealed without complex modeling and identify aspects of the data that may be explored further. References: [1] Margolskee, A., Khanshan, F., Stein, A., Ho, Y., and Looby, M. (2019) Exploratory Graphics (xGx). Pharmacometrics, Novartis Institutes for Biomedical Research, Cambridge. (Available from https://opensource.nibr.com/xgx/) [2] Margolskee, A., Baillie, M., Magnusson, B., Jones, J. and Vandemeulebroecke, M. (2018) Graphics principles cheat sheet. Biostatistical Sciences and Pharmacometrics, Novartis Institutes for Biomedical Research, Cambridge. (Available from https://graphicsprinciples.github.io/)",Alison Margolskee,Novartis,,
1,12:00 PM,talk,Interactive Visualization of Standardized CDISC-SEND-Formatted Toxicology Study Data Using R Shiny,"The standardization of nonclinical study data by the Clinical Data Interchange Standards Consortium (CDISC) via the Standard for Exchange of Nonclinical Data (SEND) has created an opportunity for the collaborative development and use of open source software solutions to analyze and visualize toxicology study data. Shiny is an open source R package that facilitates the development of user-friendly, web-based applications. The Pharmaceutical Users Software Exchange (PhUSE) consortium has provided a platform for stakeholders throughout the pharmaceutical industry to collaboratively build and share tools, e.g. R Shiny applications, to enhance the effectiveness and efficiency of drug development. The modeling of standard repeat-dose toxicology study endpoints, e.g. body weights, clinical signs, clinical pathology, histopathology, toxicokinetics, etc., in SEND has created new opportunities for dynamic, interactive visualization of study data above and beyond the static tables and figures typically included in static study reports. For example, clinical pathology data from nonclinical toxicology studies can be difficult to digest when presented as group means in data tables, due to the large number of potentially correlated analytes collected across treatment groups, sexes, and potentially multiple timepoints. An R Shiny application has been developed to allow end users to comprehensively examine these datasets, using a variety of analytical and visualization methods, with relative ease. The application is publicly hosted on shinyapps.io, and the source code can be found on the PhUSE GitHub website.",Kevin Snyder,FDA,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Snyder-Visualization_of_SEND_Toxicity_Study.pptx,
1,12:10 PM,talk,Using RStudio.Cloud to advance R proficiency: a crowdsourcing training experience,"As the Pharmaceutical sector boosts its interactions with regulatory agencies using R programming as one key instrument for drug development submissions, we face a dilemma that several members of statistics and statistical programming teams are not currently advanced R programmers. For many years SAS has been a powerful tool in the data analysis repertoire of pharma statisticians however the recent development of automation capabilities such as RMarkdown and R/Shiny have created a new venue to expedite access to consumable information in the form of reports, presentations or interactive graphics that can be produced efficiently and in standard format for all phases of a drug development or submission process. At Janssen we aim to improve the literacy in R programming and achieve nearly 100% adhesion by statistics and statistical programming teams in the coming 2-3 years. To achieve this goal, we are leveraging all types of training formats, from online training, to in-house instructor led seminar, to one-on-one mentoring. One of the key methods we have been developing is the use of RStudio.Cloud as a platform for internal crowd-led hands-on workshops where statisticians/programmers are ""thought"" to solve on-the-job real problems ranging from visualization to automated reports. In this presentation we will discuss our experience creating this program and share lessons learned, mistakes and successes.",Paulo Bargo,Janssen,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Bargo-Using_RStudio_Cloud_to_advance_R_proficiency.pdf,
1,12:30 PM,break,Lunch,,,,,
1,1:30 PM,talk,Updates on Analyzing Clinical Trials Data with R,"At R in Pharma 2018, I gave a workshop and a presentation on analyzing clinical trials data with R. Since then much has happened at Roche/Genentech with regard to analyzing clinical trials data with R: our R-based projects got funded in order to extend our R tools and make them production ready. Since then we have created an R developer team that uses the SCRUM framework to work on our R tools. We also have subject-matter expert teams that translate the business knowledge into documentation and R code. Much effort has gone into setting up a CI/CD environment and defining a GitHub workflow that enabled our teams to collaborate efficiently and to keep the code quality high. In this presentation, I will first introduce the team structures, workflows, CI/CD environment and give some updates on the software development side. Finally, I will conclude with a brief update on our discussions around open sourcing and collaboration within the pharma industry and use this opportunity to start a conversation with the audience.",Adrian Waddell,Roche / Genentech,,
1,1:50 PM,talk,R Packages for Analyzing Clinical Trials Data with R Focusing on Safety And Early Efficacy,"The R shiny-based nest framework (previously named teal) has been proven valuable in exploratory settings and supporting strategic decision meetings. To allow more clinical studies to be able to adopt this agile framework in a wider range, we've developed a R package osprey and its accompanying R-shiny modules package teal.osprey, for the summarization, analysis and visualization of safety and early efficacy data. At its current development stage, the packages provide standard safety tables and several plots, covering adverse events, disposition, tumor burden, response data and a few other domains. The packages inherited the code reproducibility and interactive dynamic filtering functionality, allowing seamless integration with the previously-existing modules in the nest framework.",Nina Qi,Roche / Genentech,,
1,2:00 PM,talk,Package management,,Devin Pastoor,Metrum Research Group,,
1,2:20 PM,talk,"Shinytized R Markdown: A Potent OTC Alternative to 1,3,7-Trimethylxanthine & Currently Indicated for NDA Document Generation, Among Others","Providing a Study Data Reviewer's Guide for Clinical Data to accompany the SDTM datasets, define.xml, and annotated CRF in a submission gives additional information to help the FDA review team. The guide is traditionally authored using MS Word - a 100% manual and labor intensive process with its inherent shortcomings often exposed and aggravated during the usually frenzied sponsor submission process. R offers a more efficient solution with greater reproducibility: Programmatic document generation facilitated by Shiny and R Markdown. Shiny not only manages R Markdown knitting but gives the sponsor staff, who oftentimes are unfamiliar with R, the ability to quickly leverage R with just a crash course in Markdown. An example of applying Shiny and R Markdown to generate the Study Data Reviewer's Guide for Clinical Data will be presented.",Mark Rothe,Sanofi,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Rothe-Shinytized_R_Markdown.pdf,
1,2:30 PM,talk,Collaborating at scale: managing an enterprise analytical computing ecosystem,"In a large organization, collaboration faces many obstacles. Groups may inadvertently reinvent functionality and expend redundant effort. Siloing may impede aggregation and comparison of results. Analysts may not be aware of potential collaborators. However, a shared computational analysis environment, supported by centrally developed infrastructure and well-defined policies, enables discoverability, facilitates reuse, promotes communication between analysts, and improves comparability of results. We will present how we are pursuing this vision at Genentech.",Rena Yang,Roche / Genentech,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Yang-Collaborating_at_Scale.pdf,
1,2:50 PM,talk,Embrace R in Pharma - building internal R community and establishing fit-for-purpose R pilots,"R is the dominant language in modern quantitative science, however it is still not widely used in pharma industry. In this talk I will share learnings in building an internal R user community in a large global organization, via efforts including cataloging existing works, coordinating R adoption pilots and trainings, etc. In addition, I will share our experiences and challenges in building a streamlined workflow with an automated writing component to enhance efficiency and reproducibility in a recent health authority interaction, towarding our mission of bringing therapies to patients faster.",Ning Leng,Roche / Genentech,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Leng-Embrace_R_in_Pharma.pdf,
1,3:00 PM,talk,Re-envisioning Clinical Content Delivery in the Open Source World,"Content delivery in preparation for filing a clinical study report requires robust tooling for quickly and reproducibly compiling analysis of study data. Traditionally, this reproducibility has stemmed from one-time, rigorous validation of a development environment and analytic workflow. More recently, this paradigm has shifted to match modern software development principles, transitioning toward continuous monitoring of software validation and quality.
 
I'll share our developing perspectives on validation and reproducibility, driven by a need to leverage open source tools. This vision leans on open source software such as R and its package ecosystems, publicly maintained containerized environments like the rocker project and cross-industry risk assessment via the R Validation Hub. By treating analysis as a software process in the content pipeline transforming raw data into analytic results, we can take advantage of the continuous deployment workflows prevalent in the software development world to shorten our filing timelines, while simultaneously delivery a more reproducible product to our health authority partners.",Doug Kelkhoff,Roche / Genentech,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Kelkhoff-Reenvisioning_Clinical_Content_Delivery_in_the_Open_Source_World.pdf,
1,3:20 PM,talk,The use of R for improved reproducibility of biomarker detection in liquid biopsies,"Research reproducibility has been heatedly discussed in recent years. Some authors have pointed out that a large portion of published research findings is incorrect and/or irreproducible. Some state that the medical literature is as reliable as expected. Despite the true state of the research literature, we can agree that reproducibility is of greatest importance to biomarker detection, including in the context of drug discovery and development. Research reproducibility may become a challenge in the current research community, because of the interdisciplinary nature of modern studies and latent gaps between the advancement of technology and the ability to analyze the resulting data. In this presentation, we will describe the reproducibility challenges of biomarker detection in liquid biopsies, which hold prevalent promises in disease diagnosis, treatment, and prevention. Our study shows that proper development and use of R packages can give a significant contribution to reproducible, high-quality, and cutting-edge research in nucleic acid biomarker detection, such as detection of novel circulating microRNA biomarkers.",Vivian Zhuang,FDA,,
1,3:30 PM,break,Break,,,,,
1,3:50 PM,keynote,Breaking the Speed Limit: How R Gets Faster,,Marianna Foos,bluebird bio,https://docs.google.com/presentation/d/1U5IetIuyLt2mnwljjP6L04I2veLGzDOpJtDP60veuPY/mobilepresent?slide=id.p,
1,4:35 PM,talk,Leveraging multiple R tools to make effective pediatric dosing decisions,"R Shiny apps allow for dynamic, interactive, real-time integration of knowledge within a drug-development program to support decision making. Here, an R Shiny app was used to explore the pharmacokinetic and pharmacodynamic effects of different dosing regimens of the anti IL-17 human mAb CosentyxÂ® (secukinumab) in pediatric patients. Secukinumab has been studied and approved to treat psoriasis in adult patients. Models which describe the dose-exposure-response relationships in adults (Lee et al., Clin Pharmacol Ther, 2019 and FDA, Medical Reviews BLA 125504, 2015) were used in the mrgsolve simulation package to explore these relationships in pediatric patients. The prior adult knowledge, used in conjunction with the computational infrastructure leveraged through R, the Shiny app, mrgsolve, and Rcpp, allows researchers to explore various dosing regimens in a difficult-to-study patient population. The tools and approaches described here have been routinely used to support regulatory interactions (ex. PIP) involving pediatric dosing.",Jeannine Fisher,Metrum Research Group,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Fisher-Pediatric_Dosing_Decisions.pdf,
1,4:45 PM,talk,Using Machine Learning and Interactive Graphics to Find New Cancer Targets,"GlaxoSmithKline is searching for new oncology drug targets. We have CRISPR knockout data for many cancer cell lines and many genes. For these same cell lines, we also have genomic data --somatic mutations, copy number variants, and gene expression. We use machine learning (random forests) to find predictive relationships between genomic features and cell line growth under knockout. Then we use GLASSES, a shiny app, to share the results with biologists. GLASSES lets scientists interactively explore key relationships and discover novel cancer vulnerabilities.",David Cooper,GSK,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Cooper-Using_ML_and_Interactive_Graphics_to_Find_New_Cancer_Targets.pptx,
1,5:05 PM,talk,Machine learning workflow management with drake,"Machine learning workflows can be difficult to manage. A single round of computation can take several hours to complete, and routine updates to the code and data tend to invalidate hard-earned results. You can enhance the maintainability, hygiene, speed, scale, and reproducibility of such projects with the drake R package. drake resolves the dependency structure of your analysis pipeline, skips tasks that are already up to date, executes the rest with optional distributed computing, and organizes the output so you rarely have to think about data files. This talk demonstrates a deep learning project with drake-powered automation.",Will Landau,Eli Lilly,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Landau-Machine_Learning_Workflow_Management_in_R.pdf,
1,5:15 PM,talk,"An R package for Data Science and *Deep Visualization* of a complex clinical database","We define and illustrate a ""deep visualization"" paradigm for the analysis of a relatively large and complex clinical database for psoriasis (PSO) and psoriatic arthritis (PsA). This paradigm supports a growing number of machine learning and exploratory analyses, and it provides a framework for Shiny applications and dashboards used to communicate results with internal and external clinicians. Our R platform implements a ""whole-patient"" data view including omics, imaging, and hundreds of anatomical assessments (scores) on multiple tissues, such as skin, joints, bones, entheses, etc. The package makes extensive use of anatomical metadata objects implemented as reference classes (Chambers, 2016), both for computing over anatomical structures and for visualizing disease state both at specific anatomical locations and at the patient-level. We present examples including visualization of bone and joint structural damage assessment scores, clustering of patients according to their disease trajectories, and association of pain to clinical endpoints over time.",David James,Novartis,,
2,8:15 AM,coffee-session,Shiny for Early Drug Discovery Research,,Gordon Turner,Novartis,,
2,8:15 AM,coffee-session,Shiny in Production,,Kelly O'Briant,RStudio,https://speakerdeck.com/kellobri/shiny-in-production-building-bridges-from-data-science-to-it,
2,8:15 AM,coffee-session,SAS & R,,Bella Feng // Nate Mockler,Amgen // Biogen,,
2,8:45 AM,break,Break,,,,,
2,9:00 AM,opening-remarks,Opening Remarks,,Xiao-Li Meng,Harvard University,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Meng-Opening_Remarks_Day_2.pptx,
2,9:00 AM,keynote,Multi-modal data integration,,Aedin Culhane,Dana-Farber,https://github.com/rinpharma/2019_presentations/blob/master/talks_folder/2019-Culhane-Multi_Modal_Data_Integration.pdf,
2,9:15 AM,talk,Your Missing Step in Reproducible R Programming: Continuous Deployment,"The past few years have shown vast improvements in workflows for reproducible and distributable research within the R ecosystem. At satRday Chicago everyone in the audience said they used R Markdown, however only one person raised their hand when asked if they could associate their reports back to the code version that generated it. Since continuous integration is quickly becoming commonplace in the R community, continuous deployment (CD) is a logical and easy step to add to your workflow to enhance reproducibility. I will demo associating R Markdown to the code version that produced it and automating the build and release of both executable and cloud-based Shiny apps. Finally, an announcement of the electricShine package for creating Electron based Shiny apps will highlight the power of using CD with production-level Shiny apps.",Chase Clark,University of Illinois at Chicago,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Clark-Continuous_Deployment.pdf,
2,10:00 AM,talk,"From playing in the backyard to designing one: Shiny transforms study designs, data analyses and statistical thinking of oncology in vivo group at Janssen","In vivo studies are crucial to the discovery and development of novel drugs and are conducted for proof-of-concept validation, FDA applications and to support clinical trials. Appropriate study design, data analyses and interpretation are essential in providing the knowledge about the drug efficacy and safety within a living organism. With drug discovery science moving forward at an ever-accelerating rate data analyses software are not always capable to offer appropriate toolset for data analyses. In the absence of a proper tool, oncology in vivo scientists at Janssen R&D needed comprehensive analysis platform to conduct appropriate and efficient analyses of in vivo data to insure quality and speed of decision-making. INVIVOLDA shiny application was developed to fulfill the gap.
 
INVIVOLDA offers interactive and animated graphics for data explorations and powerful linear mixed effect modeling framework for longitudinal data analysis. With implemented decision trees and statistical report generation it streamlines statistical analyses of in vivo longitudinal data.
 
INVIVOLDA success lead to more requests for Shiny applications for analyses and design of experiments in oncology in vivo group. Multiple statistical trainings were subsequently conducted to educate biologists on statistical methods implemented in Shiny applications. Once completed, comprehensive framework of Shiny apps will enhance statistical knowledge and thinking, transform the way experiments are designed and analyzed and ensure traceable and reproducible research and efficient decision making in oncology in vivo group at Janssen.",Volha Tryputsen,Janssen,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Tryputsen-From_Playing_in_the_Backyard_to_Designing_One.pdf,
2,10:20 AM,talk,ModViz POP: R-Shiny Based PK/PD Interface for Empowering Teams to Perform Real-Time Simulations,"Objectives: Demonstrate an interactive and dynamic visualization tool, ModViz POP, for simulating ordinary differential equations based PK/PD models with variability.
 
Methods: ModViz POP has an in built PKPD ODE library of models based on the compartmental nomenclature for simulating standard IV bolus, infusion and first order absorption scenarios. It also gives the user the ability to plug in a model from local directory to quickly simulate a model of interest. Users can also simulate from a project library which serves as a repository of final PK/PD models developed by individual project teams. Beyond the PK/PD models, it can handle complex QSP models and PBPK models equally well.
 
Enhanced R packages, HTML/CSS, LATEX in combination with Shiny were used and provided an elegant and powerful programming framework for turning models into a web application with dynamic visualization and automated report writing. The user interface consists of several key inputs for performing the simulations.
 
A tabbed navigation allows the user to visualize the plots, input parameters, derived values and equations. It provides the ability to download the underlying model, plots, simulated data or a comprehensive report consisting of all the key inputs and outputs of the simulations. The Help button provides a link to documentation with detailed instructions on different components of the interface.
 The interface also includes advanced features where users can overlay external data on over simulated data, set a certain simulation scenario as a reference or carry out sensitivity analysis based simulations.
 
Conclusions: This easy to use interface can serve as a valuable tool for teams to explore and evaluate potential scenarios and thus facilitate collaborative decision making in the drug discovery and development paradigm.
 
References:
Kyle T. Baron et. al. mrgsolve: Simulate from ODE-Based Population PK/PD and Systems Pharmacology Models. 2017",Pavan Vaddady,Merck,,
2,10:30 AM,break,Break,,,,,
2,10:50 AM,talk,Building Open Source Tools for Safety Monitoring: Advancing Research Through Community Collaboration,"The Interactive Safety Graphics (ISG) workstream of the ASA-DIA Biopharm Safety Working Group is excited to introduce the safetyGraphics package: an interactive framework for evaluating clinical trial safety in R using a flexible data pipeline. Our group seeks to modernize clinical trial safety monitoring by building tools for data exploration and reporting in a highly collaborative open source environment. At present, our team includes clinical and technical representatives from the pharmaceutical industry, academia, and the FDA, and additional contributors are always welcome. The current release of the safetyGraphics R package includes graphics related to drug-induced liver injury. The R package is paired with an in-depth clinical workflow for monitoring liver function created by expert clinicians based on medical literature. safetyGraphics features interactive visualizations built using htmlwidgets, a Shiny application, and the ability to export a fully reproducible instance of the charts with associated source code. To ensure quality and accuracy, the package includes more than 300 unit tests, and it has been vetted through a beta testing process that included feedback from more than 20 clinicians and analysts. The Shiny application can easily be extended to include new charts or applied to other disease areas due to its modular design and generalized charting framework. Several companies have adapted the tool for their own use, leading to interesting discussions and paving the way for enhancements, which demonstrates the power of open source and community collaboration.",Becca Krouse,Rho,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Krouse-Building_Open_Source_Tools_for_Safety_Monitoring.pptx,
2,11:10 AM,talk,"It's Not What's on the Outside, but It's What's on the Back-end That Matters: The World Beyond CSV Files","Start browsing through R tutorials online and it won't take long to stumble across a read.csv statement. CSV files serve well for detached, static analyses. They tend fail, however, when tasked with storing large, dynamic data sets being accessed interactively by globally dispersed, concurrent users. Often the go to in this situation is a traditional relational database management system such as Oracle or MySQL, but there are other options! This talk will review the various back-ends, along with potential considerations, Merck's Digital Proactive Process Analytics group has implemented to support various Shiny applications, dashboards, and automated data analysis pipelines.",Marcus Adams,Merck,,
2,11:30 AM,talk,Improve installation sequences for R package cohorts,"The installation of a cohort of R packages can constitute a challenge; especially considering different dependency types, package versions, overlapping namespaces and varying risks assigned to each of the packages. At the same time, the number of R packages to be installed grows exponentially with each new package added. Their complex dependencies may create conflicts. In this context, the R admin is often confronted with a cohort of packages without knowing the package of interest. We use statistical analysis techniques from the field of complex network analysis in order to shed light into the non-trivial dependency structures of package cohorts. Furthermore, we simplify the network graph to find improved installation sequences for a pre-selected cohorts of R packages. We reduce large package cohorts to a sufficient shortlist of packages, whose installation automatically pulls in other packages via dependencies without causing conflicts. The build time of a library may be greatly reduced. As a byproduct, we generate a graph of the build on the exact dependency tree and actual versions used for auditing and change control in the regulated workflows. This strategy also allows for the identification of high-risk packages and their importance in the dependency tree.",Juliane Manitz,EDM Serono,,
2,11:40 AM,talk,Evaluating the performance of advanced causal inference methods applied to healthcare claims data,"Cohort studies of treatments developed from healthcare claims often have hundreds of thousands of patients and up to several thousand measured covariates. Therefore, new causal inference methods that combine ideas from machine learning and causal inference may improve analysis of these studies by taking advantage of the wealth of information measured in claims. In order to evaluate the performance of these methods as applied to claims-based studies, we use a combination of real data examples and plasmode simulation, implemented in R package 'plasmode', which creates realistic simulated datasets based on a real cohort study. In this talk, I will give an overview of our progress so far and what is left to be done.",Jessica Myers Franklin,Harvard University,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Franklin-Advanced_Causal_Inference_Methods_Applied_to_Healthcare_Claims_Data.pptx,
2,12:00 PM,talk,Tidysq for Working with Biological Sequence Data in ML Driven Epitope Prediction in Cancer Immunotherapy,"We are amidst a data revolution. Just the past 5 years, the cost of sequencing a human genome has gone down approximately 10-fold. This development moves equally fast within areas such as mass spectrometry, in vitro immuno-peptide screening a.o. This facilitates the search for bio-markers, biologics, therapeutics, etc. but also redefines the requirements for storing, accessing and working with data and the skillset of bio data scientists. In this talk I will present tidysq, an R-package aiming at extending the Tidyverse framework to include (tidy) bio-data-science / bioinformatics. Tidysq will be presented in context with current status in ML driven (neo)epitope prediction within cancer immunotherapy.",Leon Eyrich Jessen,Technical University of Denmark,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Jessen-Tidysq_Cancer_Immunotherapy.html,
2,12:10 PM,break,Lunch,,,,,
2,12:30 PM,talk,This one is not like the others: Applicability Domain methods in R,"Even though a model prediction can be made, there are times when it should taken with some skepticism. For example, if a new data point is substantially different from the training set, its predicted value may be suspect. In chemistry, it is not uncommon to create an ""applicability domain"" model that measures the amount of potential extrapolation from the training set. The applicable package will be used to demonstrate different method to measure how much a new data point is an extrapolation from the original data (if at all).",Max Kuhn,RStudio,https://github.com/topepo/R-Pharma-2019,
2,1:30 PM,talk,Accelerating Chemistry Research through the Integration of Data Science with High-Throughput Experimentation,The development of a streamlined data-aggregation methodology utilizing the statistical programming language R is described. The centralization of high-throughput experimentation data enabled the use of statistics and data exploration methods within R to accelerate the identification and optimization of chemical reactions.,Jason Stevens,BMS,,
2,1:50 PM,talk,Reproducible shiny apps with shinymeta,"Shiny makes it easy to take domain logic from an existing R script and wrap some reactive logic around it to produce an interactive webpage where others can quickly explore different variables, parameter values, models/algorithms, etc. Although the interactivity is great for many reasons, once an interesting result is found, it's more difficult to prove the correctness of the result since: (1) the result can only be (easily) reproduced via the Shiny app and (2) the relevant domain logic which produced the result is obscured by Shiny's reactive logic. The R package shinymeta provides tools for capturing and exporting domain logic for execution outside of a Shiny runtime (so that others can reproduce Shiny-based result(s) from a new R session).",Carson Sievert,RStudio,https://talks.cpsievert.me/20190823/,
2,2:00 PM,talk,Shiny apps for accelerating early drug discovery research,"Scientists in drug discovery research utilize a wide variety of instrumentation and techniques to advance their research. While instrumentation vendors often provide software tools to deal with data wrangling and visualization, a simple collection of isolated tools often fails to address the scale and overall scope of the data analysis encountered in discovery research. This can lead to lost productivity as scientists work to process, collate and summarize their work across various informatics systems. Shiny has seen increasing use in Pharma clinical research. On the other hand, Shiny apps are also transforming discovery research by putting powerful data wrangling, visualization and reporting tools into the hands of bench scientists. To solve the aforementioned problems in drug discovery research, we developed a suite of tools using Shiny to automate data wrangling, integration, visualization and reporting. Examples will be presented in areas such as automated signal processing and batch analysis of electrocardiogram data, collection and visualization of biomarker and physiology measurements from pharmacology studies, and access to a high performance computation cluster for non-experts. These Shiny tools and have shown value by increasing productivity and accelerating scientific research.",Gordon Turner,Novartis,,
2,2:20 PM,break,Break - stretch your legs!,,,,,
2,2:30 PM,talk,Using R to foster the communication with non-statisticians on Bayesian dose escalation models,"Bayesian model-based dose-escalation designs, including one and two parameter logistic regression models, have meanwhile proven themselves in Phase I dose-escalation trials (Iasonos and O'Quigley, 2014 [1]). Compared to rule/algorithm-based designs such as the 3+3 design, model-based designs have the advantage of being more flexible in choosing the target toxicity rate and cohort size. Bayesian modeling allows to combine prior knowledge of the drug (e.g. from animal tox studies, data from comparator drugs or data from other studies) with the observed data from the current trial. The model-based approach accounts for uncertainty, optimize dose recommendations (balance of risk versus benefit for patients) and allows for dose de-escalation as well as dose re-escalation. Recent research has shown that model-based approaches are more reliable in estimating the maximum tolerated dose (MTD) and allocating less patients to ineffective or excessively toxic doses (Jaki et al., 2019 [2]). Because of their higher complexity, model-based designs are still seen critical among clinicians (Le Tourneau et al., 2012 [3]), thus the classical 3+3 design is still widely implemented due to its simplicity and transparency. Conaway et al., 2019 [4] have highlighted that the choice of design in early phase affects the outcome of the drug development process, therefore more attention should be paid to early-stage designs. In this talk we will showcase how we bring Bayesian dose-escalation models closer to non-statisticians by means of R. We will discuss how we plan, implement and communicate the dose-escalation design to the clinicians. Moreover, we show how we present our results to the safety monitoring committee (SMC) and how we support the SMC in dose escalation decisions. We use a simple data example to illustrate the proposed methodology. All will be discussed within the context of using R as primary tool. [1] Iasonos, A. and O'Quigley, J (2014). Adaptive Dose-Finding Studies: A Review of Model-Guided Phase I Clinical Trials. Journal of clinical oncology, 2014; 32(23). [2] Jaki, T., Clive, S. and Weir, C.J. (2013). Principles of dose finding studies in cancer: a comparison of trial designs. Cancer Chemother Pharmacol 71:1107-1114. [3] Le Tourneau C, Gan HK, Razak ARA, Paoletti X (2012). Efficiency of New Dose Escalation Designs in Dose-Finding Phase I Trials of Molecularly Targeted Agents. PLoS ONE 7(12): e51039. [4] Conaway, M.R. and Petroni, G.R. (2019). The impact of early phase trial design in the drug development process. Clinical Cancer Research.",Marianna Grinberg,Merck,,
2,2:40 PM,talk,Prediction of maternal-fetal exposures of CYP450-metabolized drugs using physiologic pharmacokinetic modeling implemented in R and mrgsolve.,"Physiologically based pharmacokinetic (PBPK) models are used extensively in drug development to address of number of problems. However, most PBPK applications have limited knowledge sharing impact because they are implemented in closed, proprietary software. Much of the physiologic data and knowledge required for these models is publically available or available in the pre-competitive space. To this end, we've engaged in the development of open science PBPK models, using R as the scaffolding for this work. In particular, our group has developed the mrgsolve R package which utilizes Rcpp to compile models of systems of ordinary differential equations. One example is the development of a PBPK model to predict maternal/fetal exposures for drugs that are primarily metabolized by liver CYP450 enzymes throughout pregnancy. This model aims to utilize a quantitative understanding of the physiological and biochemical changes that occur throughout pregnancy to inform clinical pharmacology decisions where clinical trials cannot. The model was validated against the observed data of 5 different drugs: midazolam, metoprolol, caffeine, nevirapine, and artemether. A series of local sensitivity analyses followed by parameter optimization further improved model predictions using the mrgsolve and nloptr R packages. The developed maternal-fetal PBPK model in its flexible open-source implementation provides a transparent, platform-independent, and reproducible system for model-informed decision support while developing exposure-based dosing recommendations in maternal/fetal patient populations.",Madeleine S. Gastonguay,Metrum Research Group,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Gastonguay-Prediction_of_maternal_fetal_exposures_of_CYP450_metabolized_drugs.pdf,
2,3:00 PM,talk,Making Better Decisions,"In the early phases of clinical development, the future of a compound depends on more than just the result of hypothesis test on a single endpoint, in a single phase 2 study. We think a lot about how design choices affect immediate outcomes. GSK's Quantitative Decision Making (QDM) framework focusses on the question, ""How do we design our study in order to increase the chances that it will deliver data that will allow us to decide whether the drug should continue in development, or stop?"" The QDM Framework has been developed in R and takes advantage of the Biostatistics HPC environment, running thousands of hypothetical scenarios in close to real-time. The initiative is changing the way we plan and deliver clinical trials. Thanks to a Shiny front end, Statisticians are able to walk clinical teams through key trial design decisions in order to estimate the Probability of Success â€“ a key component in the QDM framework. This presentation will cover the core QDM concepts and present the key communication outputs created to support the process.",Andy Nicholls,Glaxosmithkline,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Nicholls-Making_Better_Decisions.pdf,
2,3:10 PM,talk,"From CDISC to TLFs, using R to support Pharmacokinetic Analyses","The data wrangling and manipulation capabilities in R make it perfectly suited for transforming raw clinical database data into structured, submission-ready CDISC datasets. By extensively using the dplyr, tidyr, and other packages in the tidyverse we create datasets that are ready for: 1. pharmacokinetic analysis (done in other software), 2. generation of tables, listings, and figures (TLFs) and 3. submission to the FDA. I'll also go over report ready TLF generation in R and how we've had great success in being able to produce beautiful and easy to read TLFs for our analysts and clients by using the ggplot2 and the officer packages.",Jessica Higgins,Nuventra Pharma Sciences,,
2,3:30 PM,break,Break,,,,,
2,3:40 PM,keynote,"Simulations, and Complex Innovative Trial Designs",,Paul Schuette,FDA,https://github.com/rinpharma/rinpharma2019program/tree/master/talks_folder/2019-Schuette-R_Simulations_and_Complex_Innovative_Trial_Designs.pdf,
2,4:00 PM,talk,Validation Framework for Assay Processing Pipelines,"In this talk I will discuss the steps that have been created for validating internally generated R packages at SCHARP (Statistical Center for HIV/AIDS Research and Prevention) and the lessons learned while creating packages as a team.
 
Housed within Fred Hutch, SCHARP is an instrumental partner in the research and clinical trials surrounding HIV prevention and vaccine development. Part of SCHARP's work involves analyzing experimental biomarkers and endpoints which change as the experimental question, analysis methods, antigens measured, and assays evolve. Maintaining a validated code base that is rigid in its output format, but flexible enough to cater a variety of inputs with minimal custom coding has proven to be important for reproducibility and scalability.
 
SCHARP has developed several key steps in the creation, validation, and documentation of R packages that take advantage of R's packaging functionality. First, the programming team works with leadership to define specifications and lay out a roadmap of the package at the functional level. Next, statistical programmers work together and approach the task from a software development view. Once the code has been developed, the package is validated according to procedures that comply with 21 CFR part 11, and leverage software development life cycle (SDLC) methodology. Finally, the package is made available for use across the team on live data. These procedures set up a framework for validating assay processing packages that furthers the ability of Fred Hutch to provide world-class support for our clinical trials.",Ellis Hughes,Fred Hutch,https://thebioengineer.github.io/post/2019-08-24-r-in-pharma/r_pharma_scharp_validation,
2,4:45 PM,talk,Shiny in Production: Building bridges from data science to IT,"We know that adopting documentation, testing, and version control mechanisms are important for creating a culture of reproducibility in data science. But once you've embraced some basic development best practices, what comes next? What does it take to feel confident that our data products will make it to production? This talk will cover case studies in how I work with R users at various organizations to bridge the gaps that form between development and production. I'll cover reasons why CI/CD tools can enhance reproducibility for R and data science, showcase practical examples like automated testing and push-based application deployment, and point to simple resources for getting started with these tools in a number of different environments.",Kelly O'Briant,RStudio,,
2,4:55 PM,talk,Identifying progression-free survival in Veterans with Diffuse Large B-Cell Lymphoma using electronic healthcare records,"Purpose: To establish a gold-standard methodology for accurately extracting progression-free survival (PFS) following Diffuse Large B-Cell Lymphoma (DLBCL) treatment using real-world electronic healthcare record (EHR) data.
 
Results: We produced an R Shiny application which can capture, annotate, and transform unstructured EHR data into structured data - specifically, treatment lines, cycles, and response criteria with corresponding dates - ready for analysis of PFS. An annotation schema for capturing real-world data was also developed. Mapping of common phrases used by clinicians in real-world practice to response criteria resulted in a dictionary of these phrases.",Debbie Morreall,University of Utah,,
2,5:15 PM,talk,Democratizing Natural Language Processing with I2E and R Shiny,The primary objective of the presentation is to share insights of democratizing powerful natural language processing tool like I2E lingumatics and open source R and Shiny. The talk will focus on how we can leverage I2E python sdk natural language processing toolkit to perform natural language processing and visualize text mining results with R and Shiny. We will present several uses of our R shiny platform called pharmine and its use cases which we developed for minining biomedical data.,Abhik Seal,Abbvie,https://github.com/rinpharma/2019_presentations/blob/master/talks_folder/2019-Seal-Democratizing_NLP_Search_Through_I2E_and_R_Shiny.pptx,